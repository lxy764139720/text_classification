{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import jieba\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\dataset\\题目一\\健康\\0.xml\n",
      "..\\dataset\\题目一\\健康\\1.xml\n",
      "..\\dataset\\题目一\\健康\\2.xml\n",
      "..\\dataset\\题目一\\健康\\3.xml\n",
      "..\\dataset\\题目一\\健康\\4.xml\n",
      "..\\dataset\\题目一\\健康\\5.xml\n",
      "..\\dataset\\题目一\\教育\\0.xml\n",
      "..\\dataset\\题目一\\教育\\1.xml\n",
      "..\\dataset\\题目一\\教育\\2.xml\n",
      "..\\dataset\\题目一\\教育\\3.xml\n",
      "..\\dataset\\题目一\\教育\\4.xml\n",
      "..\\dataset\\题目一\\教育\\5.xml\n",
      "..\\dataset\\题目一\\财经\\0.xml\n",
      "..\\dataset\\题目一\\财经\\1.xml\n",
      "..\\dataset\\题目一\\财经\\2.xml\n",
      "..\\dataset\\题目一\\财经\\3.xml\n",
      "..\\dataset\\题目一\\财经\\4.xml\n",
      "..\\dataset\\题目一\\财经\\5.xml\n"
     ]
    }
   ],
   "source": [
    "text_set = []\n",
    "initial_path = r'..\\dataset\\题目一'  # 记录初始路径\n",
    "latest_path = initial_path  # 进入子目录后记录上一级目录\n",
    "path = os.walk(initial_path)\n",
    "for path, dir_list, file_list in path:\n",
    "    if path != initial_path:\n",
    "        # 不在该数据集初始目录下\n",
    "        for file_name in file_list:\n",
    "            print(os.path.join(path, file_name))\n",
    "            xml_path = os.path.join(path, file_name)\n",
    "            xml_file = open(xml_path, 'r', encoding='utf-8')\n",
    "            xml_handle = xml_file.read()\n",
    "            bs = BeautifulSoup(xml_handle, 'xml')\n",
    "\n",
    "            contenttitleList = bs.findAll('contenttitle')\n",
    "            contentList = bs.findAll('content')\n",
    "            for i in range(len(contenttitleList)):\n",
    "                contenttitle = contenttitleList[i].get_text()\n",
    "                content = contentList[i].get_text()\n",
    "                text = (contenttitle + content).replace('\\n', '').replace(' ', '')\n",
    "                text = re.sub(r'[^\\u4e00-\\u9fa5]+', '', text)\n",
    "                text_cut = ' '.join(list(jieba.cut(text))[:200])\n",
    "                text_set.append(text_cut)\n",
    "        # 遍历完一个文件夹，输出该标签下的分词文件\n",
    "        class_name = path.split('\\\\')[-1]\n",
    "        text_set_array = np.array(text_set, dtype=str)\n",
    "        np.savetxt('./' + class_name + '.txt', text_set_array, fmt='%s', encoding='utf-8')\n",
    "        text_set = []\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}